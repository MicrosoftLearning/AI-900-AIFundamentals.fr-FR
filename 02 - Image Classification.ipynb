{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification d’images\r\n",
        "\r\n",
        "Le service cognitif *Vision par ordinateur* fournit des modèles préconstruits utiles pour le traitement des images, mais vous aurez souvent besoin  de former votre propre modèle pour la vision par ordinateur. Par exemple, supposons que la société de vente au détail, Northwind Traders, souhaite créer un système de caisse automatisé qui identifie les articles d’épicerie que les clients veulent acheter en fonction d’une image prise par une caméra à la caisse. Pour y parvenir, vous devrez entraîner un modèle de classification capable de classer les images pour identifier l’article acheté.\r\n",
        "\r\n",
        "![Robot tenant un presse-papiers et classant les images d’une pomme, d’une banane et d’une orange](./images/image-classification.jpg)\r\n",
        "\r\n",
        "Dans Azure, vous pouvez utiliser le service cognitif ***Vision personnalisée*** pour former un modèle de classification d’images à partir d’images existantes. La création d’une solution de classification d’images comporte deux éléments. Tout d’abord, vous devez former un modèle pour reconnaître différentes classes à l’aide d’images existantes. Ensuite, lorsque le modèle est formé, vous devez le publier comme un service qui peut être consommé par des applications.\r\n",
        "\r\n",
        "## Créer une ressource Vision personnalisée\r\n",
        "\r\n",
        "Pour utiliser le service Vision personnalisée, vous avez besoin d’une ressource Azure que vous pouvez utiliser pour *former* un modèle, et d’une ressource avec laquelle vous pouvez le *publier* pour le mettre à la disposition des applications. La ressource pour l’une ou l’autre (ou les deux) tâches peut être une ressource **Cognitive Services** générale ou une ressource **Vision personnalisée** spécifique. Vous pouvez utiliser la même ressource Cognitive Services pour chacune de ces tâches, ou utiliser plusieurs ressources (dans la même région) pour chaque tâche, afin de gérer les coûts séparément.\r\n",
        "\r\n",
        "Utilisez les instructions suivantes pour créer une nouvelle ressource **Vision personnalisée**.\r\n",
        "\r\n",
        "1. Sous un nouvel onglet de navigateur, ouvrez le portail Azure à l’adresse [https://portal.azure.com](https://portal.azure.com) et connectez-vous en utilisant le compte Microsoft associé à votre abonnement Azure.\r\n",
        "2. Sélectionnez le bouton **&#65291; Créer une ressource**, recherchez *Vision personnalisée*, puis créez une ressource **Vision personnalisée** avec les paramètres suivants :\r\n",
        "    - **Créer des options** : Les deux\r\n",
        "    - **Abonnement** : *votre abonnement Azure*\r\n",
        "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*\r\n",
        "    - **Nom** : *Entrez un nom unique*\r\n",
        "    - **Emplacement de formation** : *Choisissez une région disponible*\r\n",
        "    **Niveau tarifaire de formation** : F0\r\n",
        "    - **Emplacement de prédiction** : *Valeur identique à la ressource de formation*\r\n",
        "    - **Niveau tarifaire de prédiction** : F0\r\n",
        "\r\n",
        "    > **Remarque** : Si vous avez déjà un service de vision personnalisée F0 dans votre abonnement, sélectionnez **S0** pour celui-ci.\r\n",
        "\r\n",
        "3. Attendez que les ressources soient créées et notez que deux ressources Vision personnalisée sont provisionnées, une pour la formation et une autre pour la prédiction. Vous pouvez les visualiser en naviguant vers le groupe de ressources dans lequel vous les avez créées.\r\n",
        "\r\n",
        "## Créer un projet Vision personnalisée\r\n",
        "\r\n",
        "Pour former un modèle de détection d’objets, vous devez créer un projet Vision personnalisée basé sur votre ressource de formation. Pour ce faire, vous utiliserez le portail Vision personnalisée.\r\n",
        "\r\n",
        "1. Téléchargez et extrayez les images de formation à partir de https://aka.ms/fruit-images. **Remarque :** si vous ne pouvez pas accéder aux images de formation, une solution de contournement temporaire consiste à visiter la page https://www.github.com, puis la page https://aka.ms/fruit-images.  \r\n",
        "2. Sous un autre onglet du navigateur, ouvrez le portail Vision personnalisée à l’adresse [https://customvision.ai](https://customvision.ai). Si vous y êtes invité, connectez-vous à l’aide du compte Microsoft associé à votre abonnement Azure et acceptez les conditions de service.\r\n",
        "3. Dans le portail Vision personnalisée, créez un nouveau projet avec les paramètres suivants :\r\n",
        "    - **Nom** : Grocery Checkout\r\n",
        "    - **Description** : Classification des images pour les épiceries\r\n",
        "    - **Ressource** : *La ressource Vision personnalisée que vous avez créée précédemment*\r\n",
        "    - **Types de projets** : Classification\r\n",
        "    - **Types de classification** : Multiclasse (une balise par image)\r\n",
        "    - **Domaines** : Aliment\r\n",
        "4. Cliquez sur **\\[+\\] Ajouter des images**, puis sélectionnez tous les fichiers du dossier **pomme** que vous avez extrait précédemment. Téléchargez ensuite les fichiers images, en spécifiant l’étiquette *pomme*, comme ceci :\r\n",
        "\r\n",
        "![Télécharger une pomme avec l’étiquette pomme](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Répétez l’étape précédente pour télécharger les images du dossier **banane** avec l’étiquette *banane*, et les images du dossier **orange** avec l’étiquette *orange*.\r\n",
        "6. Examinez les images que vous avez téléchargées dans le projet Vision personnalisée. Il doit y avoir 15 images de chaque classe, comme ceci :\r\n",
        "\r\n",
        "![Images de fruits étiquetées ; 15 pommes, 15 bananes et 15 oranges](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. Dans le projet Vision personnalisée, au-dessus des images, cliquez sur **Former** pour former un modèle de classification à l’aide des images étiquetées. Sélectionnez l’option **Formation rapide**, puis attendez que l’itération de formation se termine (cela prend une minute environ).\r\n",
        "8. Lorsque le modèle d’itération a été formé, vérifiez les mesures de performance *Précision*, *Rappel*, et *AP*; Elles mesurent la précision de prédiction du modèle de classification et doivent toutes être élevées.\r\n",
        "\r\n",
        "## Tester le modèle\r\n",
        "\r\n",
        "Avant de publier cette itération du modèle pour que les applications puissent l’utiliser, vous devez la tester.\r\n",
        "\r\n",
        "1. Au-dessus des mesures de performance, cliquez sur **Test rapide**.\r\n",
        "2. Dans la case **URL de l’image**, saisissez `https://aka.ms/apple-image` et cliquez sur &#10132;\r\n",
        "3. Affichez les prédictions retournées par votre modèle. Le score de probabilité pour *pomme* devrait être le plus élevé, comme ceci :\r\n",
        "\r\n",
        "![Une image avec une prédiction de classe de pomme](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Fermez la fenêtre **Test rapide**.\r\n",
        "\r\n",
        "## Publier et consommer le modèle de classification des images\r\n",
        "\r\n",
        "Vous êtes maintenant prêt à publier votre modèle entraîné et à l’utiliser à partir d’une application cliente.\r\n",
        "\r\n",
        "9. Cliquez sur **&#128504; Publier** pour publier le modèle entraîné avec les paramètres suivants :\r\n",
        "    - **Nom du modèle** : groceries\r\n",
        "    - **Ressource de prédiction** : *La ressource de prédiction que vous avez créée précédemment*.\r\n",
        "\r\n",
        "### (!) Vérification \r\n",
        "Avez-vous utilisé le même nom de modèle : **groceries** ?   \r\n",
        "\r\n",
        "10. Après la publication, cliquez sur l’icône *Paramètres* (&#9881;) en haut à droite de la page **Performances** pour afficher les paramètres du projet. Ensuite, sous **Généralités** (à gauche), copiez **ID du projet**. Faites défiler la page vers le bas et collez-la dans la cellule de code située sous l’étape 13, en remplaçant la valeur **YOUR_PROJECT_ID**.\r\n",
        "\r\n",
        "![ID de projet dans les paramètres du projet](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Remarque** : Si vous avez utilisé une ressource **Cognitive Services** au lieu de créer une ressource **Vision personnalisée** au début de cet exercice, vous pouvez copier sa clé et son point de terminaison à partir de la partie droite des paramètres du projet, les coller dans la cellule de code ci-dessous et l’exécuter pour voir les résultats. Sinon, continuez à suivre les étapes ci-dessous pour obtenir la clé et le point de terminaison de votre ressource de prédiction Vision personnalisée._\r\n",
        "\r\n",
        "11. En haut à gauche de la page **Paramètres du projet**, cliquez sur l’icône *Galerie de projets* (&#128065;) pour revenir à la page d’accueil du portail Vision personnalisée, où votre projet est maintenant répertorié.\r\n",
        "\r\n",
        "12. Sur la page d’accueil du portail Vision personnalisée, en haut à droite, cliquez sur l’icône *Paramètres* (&#9881;) pour afficher les paramètres de votre service Vision personnalisée. Ensuite, sous **Ressources**, développez votre ressource **Prédiction** (<u>et non</u> la ressource Formation) et copiez ses valeurs **Clé** et **Point de terminaison** dans la cellule de code, sous l’étape 13, en remplaçant les valeurs **YOUR_KEY** et **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Vérification \r\n",
        "Si vous utilisez une ressource **Vision personnalisée**, avez-vous utilisé la ressource **Prédiction** (<u>et non</u> la ressource Formation) ?\r\n",
        "\r\n",
        "![Clé et point de terminaison de la ressource de prédiction dans les paramètres de la vision personnalisée](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Exécutez la cellule de code ci-dessous en cliquant sur le bouton **Exécuter la cellule** (&#9655;) (en haut à gauche de la cellule) pour définir les variables sur vos valeurs d’ID de projet, de clé et de point de terminaison."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\r\n",
        "cv_key = 'YOUR_KEY'\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\r\n",
        "\r\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez maintenant utiliser votre clé et votre point de terminaison avec un client Vision personnalisée pour vous connecter à votre modèle de classification de vision personnalisée.\r\n",
        "\r\n",
        "Exécutez la cellule de code suivante pour classer une sélection d’images de test en utilisant votre modèle publié.\r\n",
        "\r\n",
        "> **Remarque** : Ne vous souciez pas des détails du code. Il utilise le Computer Vision SDK pour Python pour obtenir une prédiction de classe pour chaque image dans le dossier /données/classification-image/test-fruit."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Get the test images from the data/vision/test folder\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\r\n",
        "test_images = os.listdir(test_folder)\r\n",
        "\r\n",
        "# Create an instance of the prediction service\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(16, 8))\r\n",
        "\r\n",
        "# Get the images and show the predicted classes for each one\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\r\n",
        "for i in range(len(test_images)):\r\n",
        "    # Open the image, and use the custom vision model to classify it\r\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\r\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\r\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\r\n",
        "    prediction = classification.predictions[0].tag_name\r\n",
        "    # Display the image with its predicted class\r\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\r\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\r\n",
        "    a.axis('off')\r\n",
        "    imgplot = plt.imshow(img)\r\n",
        "    a.set_title(prediction)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En principe, votre modèle de classification d’images a correctement identifié les produits d’épicerie dans les images.\r\n",
        "\r\n",
        "## En savoir plus\r\n",
        "\r\n",
        "Le service Vision personnalisée offre plus de possibilités que celles que nous avons explorées dans cet exercice. Par exemple, vous pouvez également utiliser le service Vision personnalisée pour créer des modèles *détection d’objets*, qui non seulement classifient les objets dans les images, mais identifient également des *boîtes de délimitation* qui montrent l’emplacement de l’objet dans l’image.\r\n",
        "\r\n",
        "Pour en savoir plus sur le service cognitif Vision personnalisée, consultez la [documentation Vision personnalisée](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}