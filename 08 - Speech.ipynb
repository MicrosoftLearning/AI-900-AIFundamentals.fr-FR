{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parole\r\n",
        "\r\n",
        "De plus en plus, nous nous attendons à pouvoir communiquer avec des systèmes d’intelligence artificielle (IA) en leur parlant, souvent dans l’attente d’une réponse orale.\r\n",
        "\r\n",
        "![Un robot qui parle](./images/speech.jpg)\r\n",
        "\r\n",
        "La *reconnaissance vocale* (système d’IA interprétant le langage parlé) et la *synthèse vocale* (système d’IA générant une réponse orale) sont les composants clés d’une solution d’IA basée sur la parole.\r\n",
        "\r\n",
        "## Créer une ressource Cognitive Services\r\n",
        "\r\n",
        "Pour créer un logiciel capable d’interpréter un discours audible et de répondre verbalement, vous pouvez utiliser le service cognitif **Parole**, qui offre un moyen simple de transcrire le langage parlé en texte et vice-versa.\r\n",
        "\r\n",
        "Si vous n’en avez pas encore, suivez les étapes suivantes pour créer une ressource **Cognitive Services** dans votre abonnement Azure :\r\n",
        "\r\n",
        "> **Remarque** : Si vous disposez déjà d’une ressource Cognitive Services, il suffit d’ouvrir sa page **Démarrage rapide** dans le portail Azure et de copier sa clé et son point de terminaison dans la cellule ci-dessous. Sinon, suivez les étapes ci-dessous pour en créer une.\r\n",
        "\r\n",
        "1. Dans un autre onglet du navigateur, ouvrez le portail Azure à l’adresse https://portal.azure.com, en vous connectant avec votre compte Microsoft.\r\n",
        "2. Cliquez sur le bouton **&#65291; Créer une ressource**, recherchez *Cognitive Services* et créez une ressource **Cognitive Services** avec les paramètres suivants :\r\n",
        "    - **Abonnement** : *Votre abonnement Azure*.\r\n",
        "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*.\r\n",
        "    - **Région** : *Choisissez une région disponible* :\r\n",
        "    - **Nom** : *Saisissez un nom unique*.\r\n",
        "    - **Niveau tarifaire** : S0\r\n",
        "    - **Je confirme avoir lu et compris les avis** : Sélectionné.\r\n",
        "3. Attendez la fin du déploiement. Ensuite, accédez à votre ressource Cognitive Services et, sur la page **Aperçu**, cliquez sur le lien permettant de gérer les clés du service. Vous aurez besoin de la clé et de l’emplacement pour vous connecter à votre ressource Cognitive Services à partir d’applications clientes.\r\n",
        "\r\n",
        "### Obtenir la clé et l’emplacement de votre ressource Cognitive Services\r\n",
        "\r\n",
        "Pour utiliser votre ressource Cognitive Services, les applications clientes ont besoin de sa clé d’authentification et de son emplacement :\r\n",
        "\r\n",
        "1. Dans le portail Azure, sur la page **Clés et Point de terminaison** de votre ressource Cognitive Services, copiez la **Clé 1** de votre ressource et collez-la dans le code ci-dessous, en remplaçant **YOUR_COG_KEY**.\r\n",
        "2. Copiez **Emplacement** de votre ressource et collez-le dans le code ci-dessous, en remplaçant **YOUR_COG_LOCATION**.\r\n",
        ">**Remarque** : Restez sur la page **Clés et Point de terminaison** et copiez **Emplacement** de cette page (exemple : _westus_). N’ajoutez pas d’espaces entre les mots dans le champ Emplacement. \r\n",
        "3. Exécutez le code ci-dessous en cliquant sur le bouton **Exécuter la cellule** (&#9655;) à gauche de la cellule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      },
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconnaissance vocale\r\n",
        "\r\n",
        "Supposons que vous vouliez construire un système domotique qui accepte les instructions vocales, telles que « allumer la lumière » ou « éteindre la lumière ». Votre application doit être capable de prendre l’entrée audio (vos instructions vocales) et de l’interpréter en la transcrivant en texte qu’elle peut ensuite analyser.\r\n",
        "\r\n",
        "Vous êtes maintenant prêt à transcrire la parole. L’entrée peut provenir d’un **microphone** ou d’un **fichier audio**. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reconnaissance vocale avec un fichier audio\r\n",
        "\r\n",
        "Exécutez la cellule ci-dessous pour voir le service Reconnaissance vocale en action avec un **fichier audio**. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Get spoken command from audio file\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Configure speech recognizer\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Use a one-time, synchronous call to transcribe the speech\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Play the original audio file\r\n",
        "playsound(audio_file)\n",
        "\n",
        "# Show transcribed text from audio file\r\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthèse vocale\r\n",
        "\r\n",
        "Vous avez maintenant vu comment le service Parole peut être utilisé pour transcrire la parole en texte ; mais qu’en est-il de l’inverse ? Comment convertir du texte en parole ?\r\n",
        "\r\n",
        "Eh bien, supposons que votre système domotique ait interprété une commande d’allumage de la lampe. Une réponse appropriée pourrait être de reconnaissance verbale de la commande (et d’effectuer la tâche commandée !)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Get text to be spoken\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Configure speech synthesis\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Transcribe text into speech\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Display an appropriate image \r\n",
        "file_name = response_text.lower() + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Essayez de changer la variable **response_text** en *Éteindre la lumière.* (y compris la période à la fin) et exécutez à nouveau la cellule pour entendre le résultat.\r\n",
        "\r\n",
        "## En savoir plus\r\n",
        "\r\n",
        "Vous avez vu un exemple très simple d’utilisation du Cognitive Services Parole dans ce carnet de notes. Vous pouvez en savoir plus sur la [conversion de parole en texte](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) et la [conversion de texte en parole](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) dans la documentation du service Parole."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}