{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Understanding\r\n",
        "\r\n",
        "Nous attendons de plus en plus des ordinateurs qu’ils soient capables d’utiliser l’IA pour comprendre des commandes vocales ou saisies en langage naturel. Par exemple, vous pourriez vouloir mettre en place un système domotique qui vous permette de contrôler les appareils de votre maison en utilisant des commandes vocales telles que « allumer la lumière » ou « mettre le ventilateur en marche », et faire en sorte qu’un appareil basé sur l’intelligence artificielle comprenne la commande et entreprenne l’action appropriée.\r\n",
        "\r\n",
        "![Un robot qui écoute](./images/language_understanding.jpg)\r\n",
        "\r\n",
        "## Créer des ressources de création et de prédiction\r\n",
        "\r\n",
        "Les services cognitifs de Microsoft comprennent le service Language Understanding, qui vous permet de définir *des intentions* qui sont appliquées à des *entités* en fonction des *énoncés*. \r\n",
        "\r\n",
        "Pour utiliser le service Language Understanding, vous avez besoin de deux types de ressources :\r\n",
        "\r\n",
        "- Une ressource *création* : utilisée pour définir, entraîner et tester le modèle de langage. Il doit s’agir d’une ressource **Language Understanding - Authoring** dans votre abonnement Azure.\r\n",
        "- Une ressource de *prédiction* : utilisée pour publier le modèle et traiter les demandes des applications clientes qui l’utilisent. Il peut s’agir d’une ressource **Language Understanding** ou **Cognitive Services** dans votre abonnement Azure.\r\n",
        "\r\n",
        "Vous pouvez utiliser une ressource **Language Understanding** ou **Cognitive Services** pour *publier* une application Language Understanding, mais vous devez créer une ressource **Language Understanding** distincte pour la *création* de l’application.\r\n",
        "\r\n",
        "> **Important** : Les ressources de création doivent être créées dans l’une des trois *régions* (Europe, Australie ou États-Unis). Les modèles créés dans les ressources de création européennes ou australiennes ne peuvent être déployés que vers des ressources de prédiction en Europe ou en Australie respectivement ; les modèles créés dans les ressources de création américaines peuvent être déployés vers des ressources de prédiction dans tout emplacement Azure autre que l’Europe et l’Australie. Consultez la [documentation sur les régions de création et de publication](https://docs.microsoft.com/azure/cognitive-services/luis/luis-reference-regions) pour de plus amples détails sur la correspondance entre les emplacements de création et de prédiction.\r\n",
        "\r\n",
        "1. Dans un autre onglet du navigateur, ouvrez le portail Azure à l’adresse [https://portal.azure.com](https://portal.azure.com), en vous connectant avec votre compte Microsoft.\r\n",
        "2. Cliquez sur **+ Créer une ressource**, et recherchez *Language Understanding*.\r\n",
        "3. Dans la liste des services, cliquez sur **Language Understanding**.\r\n",
        "4. Dans le panneau **Language Understanding**, cliquez sur **Créer**.\r\n",
        "5. Dans le panneau **Créer**, entrez les détails suivants et cliquez sur **Créer**\r\n",
        "   - **Créer option** : Les deux\r\n",
        "   - **Nom** : *Nom unique pour votre service*\r\n",
        "   - **Abonnement** : *Sélectionnez votre abonnement Azure*.\r\n",
        "   - **Groupe de ressources** : *Sélectionnez un groupe de ressources existant ou créez-en un*\r\n",
        "   - **Emplacement de création** : *Sélectionnez votre emplacement préféré*\r\n",
        "   - **Niveau tarifaire de création** : F0\r\n",
        "   - **Emplacement de prédiction** : *Choisissez un emplacement dans la même région que votre emplacement de création*\r\n",
        "   - **Niveau tarifaire de prédiction** : F0\r\n",
        "   \r\n",
        "6. Attendez que les ressources soient créées et notez que deux ressources Language Understanding sont provisionnées, une pour la création et une autre pour la prédiction. Vous pouvez les visualiser en naviguant vers le groupe de ressources dans lequel vous les avez créées.\r\n",
        "\r\n",
        "### Créer une application Language Understanding\r\n",
        "\r\n",
        "Pour mettre en œuvre la compréhension du langage naturel avec Language Understanding, vous créez une application, puis ajoutez des entités, des intentions et des énoncés pour définir les commandes que vous voulez que l’application comprenne :\r\n",
        "\r\n",
        "1. Dans un nouvel onglet du navigateur, ouvrez le portail Language Understanding pour la région de création où vous avez créé votre ressource de création :\r\n",
        "    - États-Unis : [https://www.luis.ai](https://www.luis.ai)\r\n",
        "    - Europe : [https://eu.luis.ai](https://eu.luis.ai)\r\n",
        "    - Australie : [https://au.luis.ai](https://au.luis.ai)\r\n",
        "\r\n",
        "2. Connectez-vous avec le compte Microsoft associé à votre abonnement Azure. Si c’est la première fois que vous vous connectez au portail Language Understanding, vous devrez peut-être accorder à l’application certaines autorisations pour accéder aux détails de votre compte. Effectuez ensuite les étapes *Bienvenue* en sélectionnant la ressource de création Language Understanding existante que vous venez de créer dans votre abonnement Azure. \r\n",
        "\r\n",
        "3. Ouvrez la page **Applications de conversation** et sélectionnez votre abonnement et votre ressource de création Language Understanding. Créez ensuite une nouvelle application de conversation avec les paramètres suivants :\r\n",
        "   - **Nom** : Home Automation\r\n",
        "   - **Culture** : Français (*si cette option n’est pas disponible, laissez-la vide*)\r\n",
        "   - **Description** : Domotique simple\r\n",
        "   - **Ressource de prédiction** : *Votre ressource de prédiction Language Understanding*\r\n",
        "\r\n",
        "4. Si un volet contenant des astuces pour créer une application Language Understanding efficace s’affiche, fermez-le.\r\n",
        "\r\n",
        "### Créer une entité\r\n",
        "\r\n",
        "Une *entité* est une chose que votre modèle de langage peut identifier et avec laquelle il peut faire quelque chose. Dans ce cas, votre application Language Understanding sera utilisée pour contrôler divers *appareils* dans le bureau, tels que des lumières ou des ventilateurs ; vous créerez donc une entité *appareil* qui inclut une liste des types d’appareils avec lesquels vous voulez que l’application fonctionne. Pour chaque type d’appareil, vous créerez une sous-liste qui identifie le nom de l’appareil (par exemple, *lumière*) et tous les synonymes qui pourraient être utilisés pour faire référence à ce type d’appareil (par exemple, *lampe*).\r\n",
        "\r\n",
        "1. Dans la page Language Understanding de votre application, dans le volet de gauche, cliquez sur **Entités**. Cliquez ensuite sur **Créer**, puis créez une nouvelle entité dénommée **appareil**, sélectionnez le type **Liste**, puis cliquez sur **Créer**.\r\n",
        "2. Dans la page **Liste des éléments**, sous **Valeurs normalisées**, saisissez **lumière**, puis appuyez sur ENTER.\r\n",
        "3. Après avoir ajouté la valeur **lumière**, sous **Synonymes**, saisissez **lampe** et appuyez sur ENTER.\r\n",
        "4. Ajoutez un deuxième élément de liste dénommé **ventilateur** avec le synonyme **AC**.\r\n",
        "\r\n",
        "> **Remarque** : Pour ce laboratoire, utilisez le texte exact en minuscules ou en majuscules comme indiqué _(exemple : lumière et **pas** Lumière)_ et n’ajoutez pas d’espaces supplémentaires. \r\n",
        "\r\n",
        "### Créer des intentions\r\n",
        "\r\n",
        "Une *intention* est une action que vous voulez exécuter sur une ou plusieurs entités ; par exemple, vous pouvez vouloir allumer une lumière ou désactiver un ventilateur. Dans ce cas, vous définirez deux intentions : une pour allumer un appareil, et une autre pour désactiver un appareil. Pour chaque intention, vous spécifierez des exemples *d’énoncés* qui indiquent le type de langage utilisé pour indiquer l’intention.\r\n",
        "\r\n",
        "> **Remarque** : Pour ce laboratoire, veuillez utiliser le texte exact en minuscules ou en majuscules comme indiqué _(exemple : « allumer la lumière » et **pas** « Atllumer la lumière »)_ et n’ajoutez pas d’espaces supplémentaires. \r\n",
        "\r\n",
        "1. Dans le volet de gauche, cliquez sur **Intentions**. Cliquez ensuite sur **Créer**, puis ajoutez une intention portant le nom **allumer** et cliquez sur **Terminé**.\r\n",
        "2. Sous le titre **Exemples** et le sous-titre **Exemple de saisie utilisateur**, saisissez l’énoncé ***allumer la lumière*** et appuyez sur **Enter** pour soumettre cet énoncé à la liste.\r\n",
        "3. Dans l’énoncé *allumer la lumière*, cliquez sur le mot « lumière » et attribuez-le à la valeur **lumière** de l’entité **appareil**.\r\n",
        "\r\n",
        "![Comment assigner le mot « lumière » à la valeur de l’entité.](./images/assign_entity.jpg)\r\n",
        "\r\n",
        "4. Ajoutez un deuxième énoncé à l’intention **allumer**, avec la phrase ***allumer le ventilateur***. Assignez ensuite le mot « ventilateur » à la valeur **ventilateur** de l’entité de **l’appareil**.\r\n",
        "5. Dans le volet de gauche, cliquez sur **Intentions** et cliquez sur **Créer** pour ajouter une deuxième intention avec le nom **éteindre**.\r\n",
        "6. Dans la page **Énoncés** de l’intention **éteindre**, ajoutez l’énoncé ***éteindre la lumière*** et attribuez le mot « lumière » à la valeur **lumière** de l’entité **appareil**.\r\n",
        "7. Ajoutez un deuxième énoncé à l’intention **éteindre**, avec la phrase ***désactiver le ventilateur***. Ensuite, connectez le mot « ventilateur » à la valeur **ventilateur** de l’entité **appareil**.\r\n",
        "\r\n",
        "### Entraîner et tester le modèle Langage\r\n",
        "\r\n",
        "Vous êtes maintenant prêt à utiliser les données que vous avez fournies sous la forme d’entités, d’intentions et d’énoncés pour entraîner le modèle Langage de votre application.\r\n",
        "\r\n",
        "1. En haut de la page Language Understanding de votre application, cliquez sur **Entraîner** pour entraîner le modèle Langage\r\n",
        "2. Lorsque le modèle est entraîné, cliquez sur **Tester**, et utilisez le volet Test pour afficher l’intention prévue pour les phrases suivantes :\r\n",
        "    * *allumer la lumière*\r\n",
        "    * *désactiver le ventilateur*\r\n",
        "    * *éteindre la lampe*\r\n",
        "    * *activer l’air conditionné*\r\n",
        "3. Fermez le volet de test.\r\n",
        "    \r\n",
        "### Publier le modèle et configurer les points de terminaison\r\n",
        "\r\n",
        "Pour utiliser votre modèle entraîné dans une application cliente, vous devez le publier en tant que point de terminaison auquel les applications clientes peuvent envoyer de nouveaux énoncés, à partir desquels des intentions et des entités seront prévues.\r\n",
        "\r\n",
        "1. En haut de la page Language Understanding de votre application, cliquez sur **Publier**. Sélectionnez ensuite **Créneau de production** et cliquez sur **Terminé**.\r\n",
        "\r\n",
        "2. Une fois le modèle publié, en haut de la page Language Understanding de votre application, cliquez sur **Gérer**. Puis, dans l’onglet **Paramètres**, notez **ID App** de votre application. Copiez-le et collez-le dans le code ci-dessous pour remplacer **YOUR_LU_APP_ID**.\r\n",
        "\r\n",
        "3. Dans l’onglet **Ressources Azure**, notez la **Clé primaire** et **URL du point de terminaison** pour votre ressource de prédiction. Copiez-les et collez-les dans le code ci-dessous, en remplaçant **YOUR_LU_KEY** et **YOUR_LU_ENDPOINT**.\r\n",
        "\r\n",
        "4. Exécutez la cellule ci-dessous en cliquant sur son bouton **Exécutez la cellule** (&#9655;) (à gauche de la cellule), et lorsque vous y êtes invité, saisissez le texte *allumer la lumière*. Le texte est interprété par votre modèle Language Understanding et une image appropriée s’affiche.\r\n",
        "\r\n",
        "### **(!) Important** : \r\n",
        "Recherchez l’invite en haut de la fenêtre. Vous devrez saisir *allumer la lumière* et appuyer sur **Enter**. \r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from python_code import luis\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    # Set up API configuration\n",
        "    luis_app_id = 'YOUR_LU_APP_ID'\n",
        "    luis_key = 'YOUR_LU_KEY'\n",
        "    luis_endpoint = 'YOUR_LU_ENDPOINT'\n",
        "\n",
        "    # prompt for a command\n",
        "    command = input('Please enter a command: \\n')\n",
        "\n",
        "    # get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, command)\n",
        "\n",
        "    # display an appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696381331
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (!) Vérification \r\n",
        "Avez-vous exécuté la cellule ci-dessus, puis saisi la phrase *allumer la lumière* à l’invite ? L’invite apparaîtra en haut de la fenêtre.  \r\n",
        "\r\n",
        "Exécutez à nouveau la cellule ci-dessus, en essayant les phrases suivantes :\r\n",
        "\r\n",
        "* *allumer la lumière*\r\n",
        "* *éteindre la lampe*\r\n",
        "* *activer le ventilateur*\r\n",
        "* *allumer la lumière*\r\n",
        "* *éteindre la lumière*\r\n",
        "* *désactiver le ventilateur*\r\n",
        "* *activer l’air conditionné*\r\n",
        "\r\n",
        "Si vous avez exécuté la cellule ci-dessus et qu’elle a affiché l’image d’un point d’interrogation, vous avez peut-être utilisé un texte ou un espacement légèrement différent de celui indiqué lorsque vous avez créé une entité, une intention ou un énoncé.\r\n",
        "\r\n",
        "> **Remarque** : Si vous êtes curieux de connaître le code utilisé pour récupérer les intentions et les entités de votre application Language Understanding, consultez le fichier **luis.py** dans le dossier **python_code**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajouter le contrôle vocal\r\n",
        "\r\n",
        "Jusqu’à présent, nous avons vu comment analyser du texte, mais les systèmes d’IA permettent de plus en plus aux humains de communiquer avec des services logiciels par le biais de la reconnaissance vocale. Pour y parvenir, le service cognitif **Speech** fournit un moyen simple de transcrire le langage parlé en texte.\r\n",
        "\r\n",
        "### Créer une ressource Cognitive Services\r\n",
        "\r\n",
        "Si vous n’en avez pas encore, suivez les étapes suivantes pour créer une ressource **Cognitive Services** dans votre abonnement Azure :\r\n",
        "\r\n",
        "> **Remarque** : Si vous disposez déjà d’une ressource Cognitive Services, il suffit d’ouvrir sa page **Démarrage rapide** dans le portail Azure et de copier sa clé et son emplacement dans la cellule ci-dessous. Sinon, suivez les étapes ci-dessous pour en créer une.\r\n",
        "\r\n",
        "1. Dans un autre onglet du navigateur, ouvrez le portail Azure à l’adresse [https://portal.azure.com](https://portal.azure.com), en vous connectant avec votre compte Microsoft.\r\n",
        "2. Cliquez sur le bouton **&#65291; Créer une ressource**, recherchez *Cognitive Services*, et créez une ressource **Cognitive Services** avec les paramètres suivants :\r\n",
        "    - **Abonnement** : *Votre abonnement Azure*.\r\n",
        "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*.\r\n",
        "    - **Région** : *Choisissez une région disponible* :\r\n",
        "    - **Nom** : *Saisissez un nom unique*.\r\n",
        "    - **Niveau tarifaire** : S0\r\n",
        "    - **En cochant cette case, je certifie que l’utilisation de ce service n’est pas faite par ou pour un service de police aux États-Unis** : Sélectionné.\r\n",
        "    - **Je confirme avoir lu et compris les avis** : Sélectionné.\r\n",
        "3. Attendez la fin du déploiement. Ensuite, allez sur votre ressource Cognitive Services, et sur la page **Démarrage rapide**, notez les clés et l’emplacement. Vous en aurez besoin pour vous connecter à votre ressource Cognitive Services à partir d’applications clientes.\r\n",
        "\r\n",
        "### Obtenir la clé et l’emplacement de votre ressource Cognitive Services\r\n",
        "\r\n",
        "Pour utiliser votre ressource Cognitive Services, les applications clientes ont besoin de sa clé d’authentification et de son emplacement :\r\n",
        "\r\n",
        "1. Dans le portail Azure, sur la page **Clés et Point de terminaison** de votre ressource Cognitive Services, copiez la **Clé 1** de votre ressource et collez-la dans le code ci-dessous, en remplaçant **YOUR_COG_KEY**.\r\n",
        "2. Copiez **Emplacement** de votre ressource et collez-le dans le code ci-dessous, en remplaçant **YOUR_COG_LOCATION**.\r\n",
        ">**Remarque** : Restez sur la page **Clés et Point de terminaison** et copiez **Emplacement** de cette page (exemple : _westus_). N’ajoutez pas d’espaces entre les mots dans le champ Emplacement. \r\n",
        "3. Exécutez le code dans la cellule ci-dessous. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696409914
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exécutez maintenant la cellule ci-dessous pour transcrire la parole à partir d’un fichier audio, et utilisez-la comme commande pour votre application Language Understanding."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from python_code import luis\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "from playsound import playsound\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "try:   \n",
        "\n",
        "    # Get spoken command from audio file\n",
        "    file_name = 'light-on.wav'\n",
        "    audio_file = os.path.join('data', 'luis', file_name)\n",
        "\n",
        "    # Configure speech recognizer\n",
        "    speech_config = SpeechConfig(cog_key, cog_location)\n",
        "    audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "    # Use a one-time, synchronous call to transcribe the speech\n",
        "    speech = speech_recognizer.recognize_once()\n",
        "\n",
        "    # Get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, speech.text)\n",
        "\n",
        "    # Get the appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "\n",
        "    # Display image \n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "    playsound(audio_file)\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696420498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayez de modifier la cellule ci-dessus pour utiliser le fichier audio **light-off.wav**.\r\n",
        "\r\n",
        "## En savoir plus\r\n",
        "\r\n",
        "Pour plus d’informations sur Language Understanding, consultez la [documentation service](https://docs.microsoft.com/azure/cognitive-services/luis/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
