{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse d’images avec le service Vision par ordinateur\r\n",
        "\r\n",
        "![Robot tenant une image](./images/computer_vision.jpg)\r\n",
        "\r\n",
        "*Vision par ordinateur* est une branche de l’intelligence artificielle (IA) qui explore le développement de systèmes d’IA capables de « voir » le monde, soit en temps réel à travers une caméra, soit en analysant des images et des vidéos. Cela est rendu possible par le fait que les images numériques ne sont essentiellement que des tableaux de valeurs numériques de pixels et que nous pouvons utiliser ces valeurs de pixels comme *des fonctionnalités* capables de former des modèles d’apprentissage automatique afin de classer des images, détecter des objets discrets dans une image, voire même de générer des résumés textuels de photographies.\r\n",
        "\r\n",
        "## Utiliser la vision par ordinateur de Cognitive Services\r\n",
        "\r\n",
        "Microsoft Azure comprend plusieurs *Cognitive Services* qui encapsulent des fonctions d’IA courantes, dont certaines peuvent vous aider à élaborer des solutions de vision par ordinateur.\r\n",
        "\r\n",
        "Le service cognitif *Vision par ordinateur* constitue un point de départ évident pour notre exploration de la vision par ordinateur dans Azure. Il utilise des modèles d’apprentissage automatique pré-formés pour analyser les images et en extraire des informations.\r\n",
        "\r\n",
        "Par exemple, supposons que Northwind Traders ait décidé de mettre en place un « magasin intelligent », dans lequel les services d’IA surveillent le magasin afin d’identifier les clients ayant besoin d’aide et de diriger les employés pour les aider. En utilisant le service Vision par ordinateur, les images prises par les caméras dans le magasin peuvent être analysées pour fournir des descriptions significatives de ce qu’elles représentent.\r\n",
        "\r\n",
        "### Créer une ressource Cognitive Services\r\n",
        "\r\n",
        "Commençons par créer une ressource **Cognitive Services** dans votre abonnement Azure :\r\n",
        "\r\n",
        "1. Sous un autre onglet du navigateur, ouvrez le portail Azure à l’adresse https://portal.azure.com, en vous connectant avec votre compte Microsoft.\r\n",
        "2. Cliquez sur le bouton **&#65291; Créer une ressource**, recherchez *Cognitive Services*, puis créez une ressource **Cognitive Services** avec les paramètres suivants :\r\n",
        "    - **Abonnement** : *Votre abonnement Azure*.\r\n",
        "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*.\r\n",
        "    - **Région** : *Choisissez une région disponible* :\r\n",
        "    - **Nom** : *Saisissez un nom unique*.\r\n",
        "    - **Niveau tarifaire** : S0\r\n",
        "    - **Je confirme avoir lu et compris les avis** : Sélectionné.\r\n",
        "3. Attendez la fin du déploiement. Ensuite, accédez à votre ressource Cognitive Services et, sur la page **Aperçu**, cliquez sur le lien permettant de gérer les clés du service. Vous aurez besoin du point de terminaison et des clés pour vous connecter à votre ressource Cognitive Services à partir d’applications clientes.\r\n",
        "\r\n",
        "### Obtenir la clé et le point de terminaison de votre ressource Cognitive Services\r\n",
        "\r\n",
        "Pour utiliser votre ressource Cognitive Services, les applications clientes ont besoin de son point de terminaison et de sa clé d’authentification :\r\n",
        "\r\n",
        "1. Dans le portail Azure, sur la page **Clés et Point de terminaison** de votre ressource Cognitive Services, copiez la **Clé 1** de votre ressource et collez-la dans le code ci-dessous, en remplaçant la valeur **YOUR_COG_KEY**.\r\n",
        "2. Copiez le **point de terminaison** de votre ressource et collez-le dans le code ci-dessous, en remplaçant la valeur **YOUR_COG_ENDPOINT**.\r\n",
        "3. Exécutez le code ci-dessous en sélectionnant la cellule et en cliquant sur le bouton **Exécuter la cellule** (&#9655;) à gauche de la cellule."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691487445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant que vous avez configuré la clé et le point de terminaison, vous pouvez utiliser le service Vision par ordinateur pour analyser une image.\r\n",
        "\r\n",
        "Exécutez la cellule suivante pour obtenir une description d’une image dans le fichier */data/vision/store_cam1.jpg*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from python_code import vision\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get the path to an image file\r\n",
        "image_path = os.path.join('data', 'vision', 'store_cam1.jpg')\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Get a description from the computer vision service\r\n",
        "image_stream = open(image_path, \"rb\")\n",
        "description = computervision_client.describe_image_in_stream(image_stream)\n",
        "\n",
        "# Display image and caption (code in helper_scripts/vision.py)\r\n",
        "vision.show_image_caption(image_path, description)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691518279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cela semble raisonnablement précis.\r\n",
        "\r\n",
        "Essayons avec une autre image."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the path to an image file\r\n",
        "image_path = os.path.join('data', 'vision', 'store_cam2.jpg')\n",
        "\n",
        "# Get a description from the computer vision service\r\n",
        "image_stream = open(image_path, \"rb\")\n",
        "description = computervision_client.describe_image_in_stream(image_stream)\n",
        "\n",
        "# Display image and caption (code in helper_scripts/vision.py)\r\n",
        "vision.show_image_caption(image_path, description)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691524330
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Là encore, la légende suggérée semble assez précise.\r\n",
        "\r\n",
        "## Analyser les fonctionnalités d’une image\r\n",
        "\r\n",
        "Jusqu’à présent, vous avez utilisé le service Vision par ordinateur pour générer une légende descriptive pour quelques images, mais vous pouvez faire beaucoup plus. Le service Vision par ordinateur offre des capacités d’analyse qui permettent d’extraire des informations détaillées telles que :\r\n",
        "\r\n",
        "- Les emplacements des types d’objets courants détectés sur l’image.\r\n",
        "- L’emplacement et l’âge approximatif des visages humains sur l’image.\r\n",
        "- Si l’image contient un contenu « adulte », « osé » ou « sanglant ».\r\n",
        "- Les étiquettes pertinentes qui pourraient être associées à l’image dans une base de données afin de faciliter sa recherche.\r\n",
        "\r\n",
        "Exécutez le code suivant pour analyser une image d’un acheteur."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the path to an image file\r\n",
        "image_path = os.path.join('data', 'vision', 'store_cam1.jpg')\n",
        "\n",
        " Specify the features we want to analyze\r\n",
        "features = ['Description', 'Tags', 'Adult', 'Objects', 'Faces']\n",
        "\n",
        "# Get an analysis from the computer vision service\r\n",
        "image_stream = open(image_path, \"rb\")\n",
        "analysis = computervision_client.analyze_image_in_stream(image_stream, visual_features=features)\n",
        "\n",
        "# Show the results of analysis (code in helper_scripts/vision.py)\r\n",
        "vision.show_image_analysis(image_path, analysis)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691530747
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## En savoir plus\r\n",
        "\r\n",
        "En plus des capacités que vous avez explorées dans ce carnet de notes, le service cognitif Vision par ordinateur permet de réaliser les opérations suivantes :\r\n",
        "\r\n",
        "- Identifier des célébrités sur des images.\r\n",
        "- Détecter des logos de marque sur une image.\r\n",
        "- Effectuer une reconnaissance optique de caractères (OCR) pour lire du texte sur une image.\r\n",
        "\r\n",
        "Pour en savoir plus sur le service cognitif Vision par ordinateur, consultez la [documentation Vision par ordinateur](https://docs.microsoft.com/azure/cognitive-services/computer-vision/)\r\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}