{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection et analyse des visages\n",
    "\n",
    "Les solutions Vision par ordinateur nécessitent généralement une solution d’intelligence artificielle (IA) pour pouvoir détecter, analyser ou identifier les visages humains. Supposons, par exemple, que l’entreprise de vente au détail Northwind Traders décide de mettre en place un « magasin intelligent », dans lequel les services d’IA surveillent le magasin pour identifier les clients ayant besoin d’aide et dirigent les employés pour les aider. L’un des moyens d’y parvenir est de procéder à la détection et à l’analyse des visages. En d’autres termes, il s’agit de déterminer s’il y a des visages sur les images et, le cas échéant, d’analyser leurs caractéristiques.\n",
    "\n",
    "![Un robot analysant un visage](./images/face_analysis.jpg)\n",
    "\n",
    "## Utilisez le service cognitif Visage pour détecter les visages\n",
    "\n",
    "Supposons que le système de magasin intelligent que Northwind Traders souhaite créer doive être capable de détecter les clients et d’analyser leurs caractéristiques faciales. Dans Microsoft Azure, vous pouvez utiliser **Visage**, qui fait partie d’Azure Cognitive Services, pour ce faire.\n",
    "\n",
    "### Créer une ressource Cognitive Services\n",
    "\n",
    "Commencez par créer une ressource **Cognitive Services** dans votre abonnement Azure.\n",
    "\n",
    "> **Remarque** : Si vous disposez déjà d’une ressource Cognitive Services, il suffit d’ouvrir sa page **Démarrage rapide** dans le portail Azure et de copier sa clé et son point de terminaison dans la cellule ci-dessous. Sinon, suivez les étapes ci-dessous pour en créer une.\n",
    "\n",
    "1. Dans un autre onglet du navigateur, ouvrez le portail Azure à l’adresse https://portal.azure.com, en vous connectant avec votre compte Microsoft.\n",
    "2. Cliquez sur le bouton **&#65291; Créer une ressource**, recherchez *Cognitive Services* et créez une ressource **Cognitive Services** avec les paramètres suivants :\n",
    "    - **Abonnement** : *Votre abonnement Azure*.\n",
    "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*.\n",
    "    - **Région** : *Choisissez une région disponible* :\n",
    "    - **Nom** : *Saisissez un nom unique*.\n",
    "    - **Niveau tarifaire** : S0\n",
    "    - **Je confirme avoir lu et compris les avis** : Sélectionné.\n",
    "3. Attendez la fin du déploiement. Ensuite, accédez à votre ressource Cognitive Services et, sur la page **Aperçu**, cliquez sur le lien permettant de gérer les clés du service. Vous aurez besoin du point de terminaison et des clés pour vous connecter à votre ressource Cognitive Services à partir d’applications clientes.\n",
    "\n",
    "### Obtenir la clé et le point de terminaison de votre ressource Cognitive Services\n",
    "\n",
    "Pour utiliser votre ressource Cognitive Services, les applications clientes ont besoin de son point de terminaison et de sa clé d’authentification :\n",
    "\n",
    "1. Dans le portail Azure, sur la page **Clés et Point de terminaison** de votre ressource Cognitive Services, copiez la **Clé 1** de votre ressource et collez-la dans le code ci-dessous, en remplaçant **YOUR_COG_KEY**.\n",
    "\n",
    "2. Copiez le **point de terminaison** de votre ressource et collez-le dans le code ci-dessous, en remplaçant **YOUR_COG_ENDPOINT**.\n",
    "\n",
    "3. Exécutez le code dans la cellule ci-dessous en cliquant sur le bouton Exécuter la cellule <span>&#9655;</span> (en haut à gauche de la cellule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez une ressource Cognitive Services, vous pouvez utiliser le service Visage pour détecter les visages humains dans le magasin.\n",
    "\n",
    "Exécutez la cellule de code ci-dessous pour voir un exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ID unique est attribué à chaque visage détecté, de sorte que votre application peut identifier chaque visage individuel détecté.\n",
    "\n",
    "Exécutez la cellule ci-dessous pour voir les ID de quelques visages d’acheteurs supplémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser les attributs du visage\n",
    "\n",
    "Visage peut faire beaucoup plus que simplement détecter des visages. Il peut également analyser les caractéristiques et les expressions du visage pour suggérer l’âge et l’état émotionnel. Par exemple, exécutez le code ci-dessous pour analyser les attributs du visage d’un acheteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D’après les scores d’émotion détectés pour le client dans l’image, celui-ci semble plutôt satisfait de son expérience d’achat.\n",
    "\n",
    "## Rechercher des visages semblables \n",
    "\n",
    "Les ID de visage qui sont créés pour chaque visage détecté sont utilisés pour identifier individuellement les détections de visage. Vous pouvez utiliser ces ID pour comparer un visage détecté à des visages précédemment détectés et trouver des visages présentant des caractéristiques similaires.\n",
    "\n",
    "Par exemple, exécutez la cellule ci-dessous pour comparer le client d’une image avec les clients d’une autre image, et trouver un visage correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaître des visages\n",
    "\n",
    "Jusqu’à présent, vous avez vu que Visage peut détecter des visages et des caractéristiques faciales, et peut identifier deux visages qui sont similaires l’un à l’autre. Vous pouvez aller plus loin en mettant en œuvre une solution de *reconnaissance faciale* qui permettra à Face de reconnaître le visage d’une personne spécifique. Cela peut être utile dans divers scénarios, comme l’étiquetage automatique des photos d’amis dans une application de médias sociaux, ou l’utilisation de la reconnaissance faciale dans le cadre d’un système de vérification d’identité biométrique.\n",
    "\n",
    "Pour voir comment cela fonctionne, supposons que la société Northwind Traders souhaite utiliser la reconnaissance faciale pour s’assurer que seuls les employés autorisés du département informatique peuvent accéder aux systèmes sécurisés.\n",
    "\n",
    "Nous allons commencer par créer un *groupe de personnes* pour représenter les employés autorisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le *groupe de personnes* existe, nous pouvons ajouter une *personne* pour chaque employé que nous voulons inclure dans le groupe, et ensuite enregistrer plusieurs photographies de chaque personne afin que Visage puisse apprendre les caractéristiques faciales distinctes de chaque personne. Idéalement, les images devraient montrer la même personne dans différentes poses et avec différentes expressions faciales.\n",
    "\n",
    "Nous allons ajouter un seul employé appelé Wendell, et enregistrer trois photographies de l’employé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Add a person (Wendell) to the group\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Get photo's of Wendell\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# Register the photos\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # Add each photo to person in person group\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # Display each image\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois la personne ajoutée et les photographies enregistrées, nous pouvons maintenant entraîner Visage à reconnaître chaque personne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, avec le modèle entraîné, vous pouvez l’utiliser pour identifier les visages reconnus dans une image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# Get the face IDs in a second image\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# Get recognized face names\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# show recognized faces\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En savoir plus\n",
    "\n",
    "Pour en savoir plus sur le service cognitif Visage, consultez la [documentation Visage](https://docs.microsoft.com/azure/cognitive-services/face/)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}