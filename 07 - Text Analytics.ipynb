{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse de texte\r\n",
        "\r\n",
        "Le traitement du langage naturel (NLP) est une branche de l’intelligence artificielle (IA) qui traite du langage écrit et parlé. Vous pouvez utiliser le NLP pour créer des solutions qui extraient le sens sémantique du texte ou de la parole, ou qui formulent des réponses significatives en langage naturel.\r\n",
        "\r\n",
        "Les *Cognitive Services* comprennent le service *Analyse de texte*, qui offre des fonctionnalités NLP prêtes à l’emploi, notamment l’identification de phrases clés dans le texte et la classification du texte en fonction du sentiment.\r\n",
        "\r\n",
        "![Un robot lisant un carnet de notes](./images/NLP.jpg)\r\n",
        "\r\n",
        "Par exemple, supposons que l’organisation fictive *Margie’s Travel* encourage ses clients à soumettre des avis sur leurs séjours à l’hôtel. Vous pourriez utiliser le service d’analyse de texte pour résumer les avis en extrayant des phrases clés, déterminer quels avis sont positifs et lesquels sont négatifs, ou analyser le texte des avis pour y trouver des mentions d’entités connues telles que des emplacements ou des personnes.\r\n",
        "\r\n",
        "## Voir les documents d’avis\r\n",
        "\r\n",
        "Commençons par jeter un coup d’œil à des avis d’hôtels laissés par des clients.\r\n",
        "\r\n",
        "Ces avis sont dans des fichiers texte. Pour les voir, exécutez le code ci-dessous en cliquant sur le bouton **Exécuter la cellule** (&#9655;) à gauche de la cellule."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Créer une ressource Cognitive Services\r\n",
        "\r\n",
        "Pour analyser le texte de ces avis, vous pouvez utiliser le service cognitif **Analyse de texte**. Pour l’utiliser, vous devez provisionner soit une ressource **Analyse de texte** soit une ressource **Cognitive Services** dans votre abonnement Azure (utilisez une ressource Analyse de texte si c’est le seul service que vous prévoyez d’utiliser ou si vous voulez suivre son utilisation séparément ; sinon, vous pouvez utiliser une ressource Cognitive Services pour combiner le service Analyse de texte avec d’autres services cognitifs ; ce qui permet aux développeurs d’utiliser un seul point de terminaison et une seule clé pour y accéder).\r\n",
        "\r\n",
        "Si vous n’en avez pas encore, suivez les étapes suivantes pour créer une ressource **Cognitive Services** dans votre abonnement Azure :\r\n",
        "\r\n",
        "> **Remarque** : Si vous disposez déjà d’une ressource Cognitive Services, il suffit d’ouvrir sa page **Démarrage rapide** dans le portail Azure et de copier sa clé et son point de terminaison dans la cellule ci-dessous. Sinon, suivez les étapes ci-dessous pour en créer une.\r\n",
        "\r\n",
        "1. Dans un autre onglet du navigateur, ouvrez le portail Azure à l’adresse https://portal.azure.com, en vous connectant avec votre compte Microsoft.\r\n",
        "2. Cliquez sur le bouton **&#65291; Créer une ressource**, recherchez *Cognitive Services*, et créez une ressource **Cognitive Services** avec les paramètres suivants :\r\n",
        "    - **Abonnement** : *Votre abonnement Azure*.\r\n",
        "    - **Groupe de ressources** : *Sélectionnez ou créez un groupe de ressources portant un nom unique*.\r\n",
        "    - **Région** : *Choisissez une région disponible* :\r\n",
        "    - **Nom** : *Saisissez un nom unique*.\r\n",
        "    - **Niveau tarifaire** : S0\r\n",
        "    - **Je confirme avoir lu et compris les avis** : Sélectionné.\r\n",
        "3. Attendez la fin du déploiement. Ensuite, accédez à votre ressource Cognitive Services et, sur la page **Aperçu**, cliquez sur le lien permettant de gérer les clés du service. Vous aurez besoin du point de terminaison et des clés pour vous connecter à votre ressource Cognitive Services à partir d’applications clientes.\r\n",
        "\r\n",
        "### Obtenir la clé et le point de terminaison de votre ressource Cognitive Services\r\n",
        "\r\n",
        "Pour utiliser votre ressource Cognitive Services, les applications clientes ont besoin de son point de terminaison et de sa clé d’authentification :\r\n",
        "\r\n",
        "1. Dans le portail Azure, sur la page **Clés et Point de terminaison** de votre ressource Cognitive Services, copiez la **Clé 1** de votre ressource et collez-la dans le code ci-dessous, en remplaçant **YOUR_COG_KEY**.\r\n",
        "2. Copiez le **point de terminaison** de votre ressource et collez-le dans le code ci-dessous, en remplaçant **YOUR_COG_ENDPOINT**.\r\n",
        "3. Exécutez le code dans la cellule ci-dessous en cliquant sur son bouton vert <span style=\"color:green\">&#9655;</span>."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Détecter la langue\r\n",
        "Commençons par identifier la langue dans laquelle ces avis sont rédigés."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraire des phrases clés\r\n",
        "\r\n",
        "Vous pouvez maintenant analyser le texte des avis des clients pour identifier des phrases clés qui donnent une idée des principaux points de discussion."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les phrases clés peuvent vous aider à comprendre les points de discussion les plus importants de chaque avis. Par exemple, un avis contenant la phrase « personnel serviable » ou « service médiocre » peut vous donner une indication des principales préoccupations de l’auteur de l’avis.\r\n",
        "\r\n",
        "## Déterminer le sentiment\r\n",
        "\r\n",
        "Il peut être utile de classer les avis comme *positifs* ou *négatifs* en fonction d’un *score de sentiment*. Là encore, vous pouvez utiliser le service Analyse de texte pour le faire."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraire les entités connues\r\n",
        "\r\n",
        "Les *entités* sont des éléments qui peuvent être mentionnés dans le texte et qui font référence à un type d’élément communément compris. Par exemple, un emplacement, une personne ou une date. Supposons que vous soyez intéressé par les dates et les lieux mentionnés dans les avis ; vous pouvez utiliser le code suivant pour les trouver."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notez que certaines entités sont suffisamment connues pour avoir une page Wikipédia associée, auquel cas le service Analyse de texte renvoie l’URL de cette page.\r\n",
        "\r\n",
        "## En savoir plus\r\n",
        "\r\n",
        "Pour plus d’informations sur le service Analyse de texte, consultez [la documentation sur le service Analyse de texte](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}